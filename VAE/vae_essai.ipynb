{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a36b83",
   "metadata": {},
   "source": [
    "## Importation des Bibliothèques Nécessaires\n",
    "\n",
    "Cette cellule importe toutes les bibliothèques Python requises pour le projet. Cela inclut des bibliothèques pour les opérations sur les fichiers (`os`, `pathlib`), le traitement des données (`numpy`, `pandas`), l'apprentissage profond (`torch`), la manipulation de molécules (`rdkit`, `selfies`), et la gestion de la configuration (`yaml`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e0a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # for file and directory operations\n",
    "import sys  # for system-specific parameters and functions\n",
    "import time  # for measuring time and delays\n",
    "\n",
    "import numpy as np  # for numerical operations\n",
    "import pandas as pd  # for data manipulation and analysis\n",
    "import torch  # for tensor operations and deep learning\n",
    "import torch.nn.functional as F  # for neural network functions like activation, loss\n",
    "import yaml  # for reading/writing .yaml configuration files\n",
    "from pathlib import Path  # for object-oriented file paths\n",
    "from rdkit import rdBase  # base RDKit module\n",
    "from rdkit.Chem import MolFromSmiles, Draw  # for molecule parsing and drawing\n",
    "from torch import nn  # for building neural network layers\n",
    "import selfies as sf  # for handling SELFIES molecular representation\n",
    "from rdkit import Chem  # optional, for SMILES validation and molecule operations\n",
    "\n",
    "import selfies as sf  # (duplicate) for handling SELFIES\n",
    "from data_loader import multiple_selfies_to_hot, multiple_smile_to_hot  # for converting molecules to one-hot format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39101d04",
   "metadata": {},
   "source": [
    "## Fonctions Utilitaires et Définition des Modèles VAE\n",
    "\n",
    "Cette cellule contient :\n",
    "1.  **Configuration Initiale** : Désactivation des logs d'erreur RDKit et définition du périphérique de calcul (GPU ou CPU).\n",
    "2.  **Fonctions Utilitaires** :\n",
    "    *   `_make_dir`: Crée un répertoire s'il n'existe pas.\n",
    "    *   `save_models`: Sauvegarde les poids de l'encodeur et du décodeur VAE.\n",
    "    *   `load_models`: Charge les poids de l'encodeur et du décodeur VAE (nécessite la définition des classes VAE).\n",
    "3.  **Classes VAE (Variational Autoencoder)** :\n",
    "    *   `VAEEncoder`: Encodeur VAE standard qui prend une représentation one-hot d'une molécule et la comprime en un espace latent (mu et log_var).\n",
    "    *   `VAEDecoder`: Décodeur VAE standard utilisant un GRU (Gated Recurrent Unit) pour reconstruire la séquence moléculaire à partir d'un point de l'espace latent.\n",
    "4.  **Fonctions pour Gumbel-Softmax** :\n",
    "    *   `sample_gumbel`: Échantillonne du bruit selon la distribution de Gumbel.\n",
    "    *   `gumbel_softmax_sample`: Effectue un échantillonnage Gumbel-Softmax pour obtenir une approximation différentiable d'un échantillonnage catégoriel.\n",
    "5.  **Classes VAE avec Gumbel-Softmax** :\n",
    "    *   `VAEEncoderGumbel`: Encodeur VAE adapté pour produire des logits pour la distribution Gumbel-Softmax.\n",
    "    *   `VAEDecoderGumbel`: Décodeur VAE qui utilise l'échantillonnage Gumbel-Softmax pour générer la séquence de sortie.\n",
    "6.  **Fonctions d'Évaluation et d'Échantillonnage** :\n",
    "    *   `is_correct_smiles`: Vérifie la validité d'une chaîne SMILES.\n",
    "    *   `sample_latent_space`: Génère des molécules en échantillonnant des points dans l'espace latent du VAE standard.\n",
    "    *   `latent_space_quality`: Évalue la qualité de l'espace latent en générant des molécules et en vérifiant leur validité et leur unicité.\n",
    "    *   `quality_in_valid_set`: Calcule la qualité de reconstruction du VAE standard sur un jeu de données de validation.\n",
    "    *   `selfies2image`: Convertit une chaîne SELFIES en une image de la molécule correspondante.\n",
    "7.  **Fonctions d'Entraînement et de Perte** :\n",
    "    *   `train_model_gumbel`: Fonction principale pour entraîner le VAE avec Gumbel-Softmax. Gère les époques, les lots, l'optimisation, la décroissance de la température Gumbel, l'évaluation et la sauvegarde des modèles.\n",
    "    *   `compute_elbo_loss_gumbel`: Calcule la perte ELBO (Evidence Lower Bound) spécifique au VAE Gumbel, composée de la perte de reconstruction et de la divergence KL.\n",
    "8.  **Fonctions pour la Divergence MMD (Maximum Mean Discrepancy)** :\n",
    "    *   `gaussian_kernel`: Calcule le noyau gaussien utilisé dans le calcul MMD.\n",
    "    *   `compute_mmd`: Calcule la divergence MMD entre deux ensembles de points (utilisé pour comparer la distribution latente à une distribution a priori, typiquement gaussienne).\n",
    "9.  **Fonction de Qualité de Reconstruction** :\n",
    "    *   `compute_recon_quality`: Mesure la similarité entre la molécule d'entrée et la molécule reconstruite par le VAE, au niveau des symboles.\n",
    "10. **Fonction de Prétraitement des Données** :\n",
    "    *   `get_selfie_and_smiles_encodings_for_dataset`: Charge un fichier CSV de SMILES, les convertit en SELFIES, détermine les alphabets et les longueurs maximales pour les deux représentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdBase.DisableLog(\"rdApp.error\")\n",
    " \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "def _make_dir(directory):\n",
    "    # Crée un dossier s'il n'existe pas\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "def save_models(encoder, decoder, epoch):\n",
    "    # Sauvegarde les poids de l'encodeur et du décodeur\n",
    "    out_dir = f\"./saved_models/{epoch}\"\n",
    "    _make_dir(out_dir)\n",
    "    torch.save(encoder.state_dict(), f\"{out_dir}/E.pth\")\n",
    "    torch.save(decoder.state_dict(), f\"{out_dir}/D.pth\")\n",
    "\n",
    "def load_models(epoch):\n",
    "    # Charge les poids de l'encodeur et du décodeur\n",
    "    out_dir = f\"./saved_models/{epoch}\"\n",
    "    encoder = VAEEncoderGumbel(in_dimension=len_max_mol_one_hot, categorical_dimension=len_alphabet, **encoder_parameter).to(device)\n",
    "    decoder = VAEDecoderGumbel(**encoder_parameter, categorical_dimension=len_alphabet, out_dimension=len_max_mol_one_hot).to(device)\n",
    "\n",
    "    torch.serialization.add_safe_globals([VAEEncoderGumbel, VAEDecoderGumbel])\n",
    "    encoder_path = f\"{out_dir}/E.pth\"\n",
    "    decoder_path = f\"{out_dir}/D.pth\"\n",
    "    if not os.path.exists(encoder_path) or not os.path.exists(decoder_path):\n",
    "        # Arrête si les fichiers de modèle sont manquants\n",
    "        print(f\"Warning: Model files not found: {encoder_path} or {decoder_path}. Please ensure the model files are in the correct directory.\")\n",
    "        sys.exit(1)\n",
    "    encoder.load_state_dict(torch.load(encoder_path))\n",
    "    decoder.load_state_dict(torch.load(decoder_path))\n",
    "    return encoder, decoder\n",
    "\n",
    "class VAEEncoder(nn.Module):\n",
    "    # Encodeur VAE classique\n",
    "    def __init__(self, in_dimension, layer_1d, layer_2d, layer_3d, latent_dimension):\n",
    "        super(VAEEncoder, self).__init__()\n",
    "        self.latent_dimension = latent_dimension\n",
    "        self.encode_nn = nn.Sequential(\n",
    "            nn.Linear(in_dimension, layer_1d),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_1d, layer_2d),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_2d, layer_3d),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.encode_mu = nn.Linear(layer_3d, latent_dimension)\n",
    "        self.encode_log_var = nn.Linear(layer_3d, latent_dimension)\n",
    "\n",
    "    @staticmethod\n",
    "    def reparameterize(mu, log_var):\n",
    "        # Échantillonnage via le trick de reparamétrisation\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Applique l'encodeur et retourne z, mu, log_var\n",
    "        h1 = self.encode_nn(x)\n",
    "        mu = self.encode_mu(h1)\n",
    "        log_var = self.encode_log_var(h1)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return z, mu, log_var\n",
    "\n",
    "class VAEDecoder(nn.Module):\n",
    "    # Décodeur VAE avec RNN\n",
    "    def __init__(self, latent_dimension, gru_stack_size, gru_neurons_num, out_dimension):\n",
    "        super(VAEDecoder, self).__init__()\n",
    "        self.latent_dimension = latent_dimension\n",
    "        self.gru_stack_size = gru_stack_size\n",
    "        self.gru_neurons_num = gru_neurons_num\n",
    "        self.decode_RNN = nn.GRU(\n",
    "            input_size=latent_dimension,\n",
    "            hidden_size=gru_neurons_num,\n",
    "            num_layers=gru_stack_size,\n",
    "            batch_first=False)\n",
    "        self.decode_FC = nn.Sequential(\n",
    "            nn.Linear(gru_neurons_num, out_dimension),\n",
    "        )\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        # Initialise l'état caché du RNN\n",
    "        weight = next(self.parameters())\n",
    "        return weight.new_zeros(self.gru_stack_size, batch_size, self.gru_neurons_num)\n",
    "\n",
    "    def forward(self, z, hidden):\n",
    "        # Décode la séquence à partir de z\n",
    "        l1, hidden = self.decode_RNN(z, hidden)\n",
    "        decoded = self.decode_FC(l1)\n",
    "        return decoded, hidden\n",
    "\n",
    "def sample_gumbel(shape, eps=1e-20):\n",
    "    # Génère du bruit gumbel\n",
    "    U = torch.rand(shape).to(device)\n",
    "    return -torch.log(-torch.log(U + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    # Applique un échantillonnage gumbel-softmax\n",
    "    y = logits + sample_gumbel(logits.size())\n",
    "    return F.softmax(y / temperature, dim=-1)\n",
    "\n",
    "class VAEEncoderGumbel(nn.Module):\n",
    "    # Encodeur VAE avec variables gumbel\n",
    "    def __init__(self, in_dimension, layer_1d, layer_2d, layer_3d, categorical_dimension, latent_dimension):\n",
    "        super(VAEEncoderGumbel, self).__init__()\n",
    "        self.latent_dimension = latent_dimension\n",
    "        self.categorical_dimension = categorical_dimension\n",
    "        self.encode_nn = nn.Sequential(\n",
    "            nn.Linear(in_dimension, layer_1d),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_1d, layer_2d),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_2d, layer_3d),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_3d, latent_dimension * categorical_dimension),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode en logits pour gumbel softmax\n",
    "        q = self.encode_nn(x)\n",
    "        return q\n",
    "\n",
    "class VAEDecoderGumbel(nn.Module):\n",
    "    # Décodeur VAE utilisant Gumbel-Softmax\n",
    "    def __init__(self, latent_dimension, layer_1d, layer_2d, layer_3d, categorical_dimension, out_dimension):\n",
    "        super(VAEDecoderGumbel, self).__init__()\n",
    "        self.latent_dimension = latent_dimension\n",
    "        self.categorical_dimension = categorical_dimension\n",
    "        self.decode_nn = nn.Sequential(\n",
    "            nn.Linear(latent_dimension * categorical_dimension, layer_3d),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_3d, layer_2d),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_2d, layer_1d),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_1d, out_dimension),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def gumbel_softmax(self, logits, temperature, hard=False):\n",
    "        # Applique gumbel softmax différentiable\n",
    "        y = gumbel_softmax_sample(logits, temperature)\n",
    "        if not hard:\n",
    "            return y.view(-1, self.latent_dimension * self.categorical_dimension)\n",
    "\n",
    "        shape = y.size()\n",
    "        _, ind = y.max(dim=-1)\n",
    "        y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "        y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "        y_hard = y_hard.view(*shape)\n",
    "        y_hard = (y_hard - y).detach() + y\n",
    "        return y_hard.view(-1, self.latent_dimension * self.categorical_dimension)\n",
    "\n",
    "    def forward(self, q, temp, hard):\n",
    "        # Décode depuis logits gumbel\n",
    "        q_y = q.view(q.size(0), self.latent_dimension, self.categorical_dimension)\n",
    "        z = self.gumbel_softmax(q_y, temp, hard)\n",
    "        return self.decode_nn(z), F.softmax(q_y, dim=-1).reshape(*q.size())\n",
    "\n",
    "def is_correct_smiles(smiles):\n",
    "    # Vérifie si un SMILES est valide\n",
    "    if smiles == \"\":\n",
    "        return False\n",
    "    try:\n",
    "        return MolFromSmiles(smiles, sanitize=True) is not None\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def sample_latent_space(vae_encoder, vae_decoder, sample_len):\n",
    "    # Génère des échantillons depuis l’espace latent\n",
    "    vae_encoder.eval()\n",
    "    vae_decoder.eval()\n",
    "    gathered_atoms = []\n",
    "    fancy_latent_point = torch.randn(1, 1, vae_encoder.latent_dimension, device=device)\n",
    "    hidden = vae_decoder.init_hidden()\n",
    "    for _ in range(sample_len):\n",
    "        out_one_hot, hidden = vae_decoder(fancy_latent_point, hidden)\n",
    "        out_one_hot = out_one_hot.flatten().detach()\n",
    "        soft = nn.Softmax(0)\n",
    "        out_one_hot = soft(out_one_hot)\n",
    "        out_index = out_one_hot.argmax(0)\n",
    "        gathered_atoms.append(out_index.data.cpu().tolist())\n",
    "    vae_encoder.train()\n",
    "    vae_decoder.train()\n",
    "    return gathered_atoms\n",
    "\n",
    "def latent_space_quality(vae_encoder, vae_decoder, type_of_encoding, alphabet, sample_num, sample_len):\n",
    "    # Évalue la qualité de l’espace latent (validité des molécules)\n",
    "    total_correct = 0\n",
    "    all_correct_molecules = set()\n",
    "    print(f\"latent_space_quality: Take {sample_num} samples from the latent space\")\n",
    "    for _ in range(1, sample_num + 1):\n",
    "        molecule_pre = \"\"\n",
    "        for i in sample_latent_space(vae_encoder, vae_decoder, sample_len):\n",
    "            molecule_pre += alphabet[i]\n",
    "        molecule = molecule_pre.replace(\" \", \"\")\n",
    "        if type_of_encoding == 1:\n",
    "            molecule = sf.decoder(molecule)\n",
    "        if is_correct_smiles(molecule):\n",
    "            total_correct += 1\n",
    "            all_correct_molecules.add(molecule)\n",
    "    return total_correct, len(all_correct_molecules)\n",
    "\n",
    " \n",
    "# Calcule la qualité de reconstruction sur un échantillon du jeu de validation\n",
    "def quality_in_valid_set(vae_encoder, vae_decoder, data_valid, batch_size):\n",
    "    data_valid = data_valid[torch.randperm(data_valid.size()[0])]\n",
    "    num_batches_valid = len(data_valid) // batch_size\n",
    "    quality_list = []\n",
    "    for batch_iteration in range(min(25, num_batches_valid)):\n",
    "        start_idx = batch_iteration * batch_size\n",
    "        stop_idx = (batch_iteration + 1) * batch_size\n",
    "        batch = data_valid[start_idx: stop_idx]\n",
    "        _, trg_len, _ = batch.size()\n",
    "        inp_flat_one_hot = batch.flatten(start_dim=1)\n",
    "        latent_points, mus, log_vars = vae_encoder(inp_flat_one_hot)  # encodeur\n",
    "        latent_points = latent_points.unsqueeze(0)\n",
    "        hidden = vae_decoder.init_hidden(batch_size=batch_size)  # initialise l'état caché\n",
    "        out_one_hot = torch.zeros_like(batch, device=device)\n",
    "        for seq_index in range(trg_len):\n",
    "            out_one_hot_line, hidden = vae_decoder(latent_points, hidden)  # décodeur\n",
    "            out_one_hot[:, seq_index, :] = out_one_hot_line[0]\n",
    "        quality = compute_recon_quality(batch, out_one_hot)  # mesure qualité reconstruction\n",
    "        quality_list.append(quality)\n",
    "    return np.mean(quality_list).item()\n",
    "\n",
    "# Convertit une chaîne SELFIES en image de molécule\n",
    "def selfies2image(s):\n",
    "    mol = MolFromSmiles(sf.decoder(s), sanitize=True)\n",
    "    return Draw.MolToImage(mol)\n",
    "\n",
    "# Entraîne le VAE avec Gumbel-Softmax\n",
    "def train_model_gumbel(vae_encoder, vae_decoder, data_train, data_valid, num_epochs, batch_size, lr_enc, lr_dec, sample_num, sample_len, alphabet, type_of_encoding, categorical_dimension, temp, hard, temp_min, anneal_rate, logger=None):\n",
    "    print(\"num_epochs: \", num_epochs)\n",
    "    int_to_symbol = dict((i, c) for i, c in enumerate(alphabet))  # dictionnaire index → symbole\n",
    "    optimizer_encoder = torch.optim.Adam(vae_encoder.parameters(), lr=lr_enc)\n",
    "    optimizer_decoder = torch.optim.Adam(vae_decoder.parameters(), lr=lr_dec)\n",
    "    data_train = data_train.clone().detach().to(device)\n",
    "    num_batches_train = len(data_train) // batch_size\n",
    "    quality_valid_list = [0, 0, 0, 0]\n",
    "    for epoch in range(num_epochs):\n",
    "        data_train = data_train[torch.randperm(data_train.size()[0])]  # mélange les données\n",
    "        start = time.time()\n",
    "        for batch_iteration in range(num_batches_train):\n",
    "            start_idx = batch_iteration * batch_size\n",
    "            stop_idx = (batch_iteration + 1) * batch_size\n",
    "            batch = data_train[start_idx: stop_idx]\n",
    "            inp_flat_one_hot = batch.flatten(start_dim=1)\n",
    "            q = vae_encoder(inp_flat_one_hot)  # encode\n",
    "            out_one_hot, qy = vae_decoder(q, temp, hard)  # decode avec Gumbel\n",
    "            loss = compute_elbo_loss_gumbel(inp_flat_one_hot, out_one_hot, qy, categorical_dimension, logger=logger)\n",
    "            optimizer_encoder.zero_grad()\n",
    "            optimizer_decoder.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_encoder.step()\n",
    "            optimizer_decoder.step()\n",
    "            if batch_iteration % 100 == 1:\n",
    "                temp = np.maximum(temp * np.exp(-anneal_rate * batch_iteration), temp_min)  # diminue la température\n",
    "            if batch_iteration % 30 == 0:\n",
    "                end = time.time()\n",
    "                quality_train = compute_recon_quality(batch, out_one_hot.view(batch.size()))\n",
    "                target = batch[0]\n",
    "                generated = out_one_hot[0].view(target.size())\n",
    "                target_indices = target.reshape(-1, target.shape[1]).argmax(1)\n",
    "                generated_indices = generated.reshape(-1, generated.shape[1]).argmax(1)\n",
    "                target_selfies = sf.encoding_to_selfies(np.array(target_indices.cpu()), int_to_symbol, \"label\")\n",
    "                generated_selfies = sf.encoding_to_selfies(np.array(generated_indices.cpu()), int_to_symbol, \"label\")\n",
    "                print(f\"\\nTarget:     {target_selfies}\")\n",
    "                print(f\"Generated:  {generated_selfies}\\n\")\n",
    "                if logger:\n",
    "                    logger.log({\n",
    "                        \"loss\": loss.item(),\n",
    "                        \"quality_train\": quality_train,\n",
    "                        \"quality_valid\": quality_valid,\n",
    "                        \"predicted\": [\n",
    "                            wandb.Image(selfies2image(target_selfies), caption=target_selfies),\n",
    "                            wandb.Image(selfies2image(generated_selfies), caption=generated_selfies)\n",
    "                        ]\n",
    "                    })\n",
    "                start = time.time()\n",
    "        quality_valid = 0.0\n",
    "        quality_valid_list.append(quality_valid)\n",
    "        quality_increase = len(quality_valid_list) - np.argmax(quality_valid_list)\n",
    "        if quality_increase == 1 and quality_valid_list[-1] > 50.:\n",
    "            corr, unique = latent_space_quality(vae_encoder, vae_decoder, type_of_encoding, alphabet, sample_num, sample_len)  # diversité et corrélation\n",
    "        else:\n",
    "            corr, unique = -1., -1.\n",
    "        \n",
    "        if quality_valid_list[-1] < 70. and epoch > 200:  # arrêt anticipé\n",
    "            break\n",
    "        if epoch > 0 and epoch % 20 == 0:\n",
    "            save_models(vae_encoder, vae_decoder, epoch)  # sauvegarde des modèles\n",
    "\n",
    "# Calcule la perte ELBO pour un VAE Gumbel\n",
    "def compute_elbo_loss_gumbel(x, x_hat, qy, categorical_dim, logger=None):\n",
    "    criterion = torch.nn.BCELoss(size_average=False)  # erreur binaire\n",
    "    recon_loss = criterion(x_hat, x)\n",
    "    log_ratio = torch.log(qy * categorical_dim + 1e-20)\n",
    "    kld = torch.sum(qy * log_ratio, dim=-1).mean()  # divergence KL\n",
    "    if logger:\n",
    "        logger.log({\n",
    "            \"reconstruction_loss\": recon_loss.item(),\n",
    "            \"kld\": kld.item(),\n",
    "        })\n",
    "    return recon_loss + kld\n",
    "\n",
    "# Noyau gaussien utilisé pour le MMD\n",
    "def gaussian_kernel(x, y):\n",
    "    x_size = x.size(0)\n",
    "    y_size = y.size(0)\n",
    "    dim = x.size(1)\n",
    "    x = x.view(x_size, 1, dim)\n",
    "    y = y.view(1, y_size, dim)\n",
    "    tiled_x = x.expand(x_size, y_size, dim)\n",
    "    tiled_y = y.expand(x_size, y_size, dim)\n",
    "    kernel_input = (tiled_x - tiled_y).pow(2).mean(2) / float(dim)\n",
    "    return torch.exp(-kernel_input)\n",
    "\n",
    "# Calcule la divergence MMD entre deux distributions\n",
    "def compute_mmd(x, y):\n",
    "    x = x.squeeze()\n",
    "    y = y.squeeze()\n",
    "    x_kernel = gaussian_kernel(x, x)\n",
    "    y_kernel = gaussian_kernel(y, y)\n",
    "    xy_kernel = gaussian_kernel(x, y)\n",
    "    mmd = x_kernel.mean() + y_kernel.mean() - 2 * xy_kernel.mean()\n",
    "    return mmd\n",
    "\n",
    "# Calcule la qualité de reconstruction en comparant les symboles générés\n",
    "def compute_recon_quality(x, x_hat):\n",
    "    x_indices = x.reshape(-1, x.shape[2]).argmax(1)\n",
    "    x_hat_indices = x_hat.reshape(-1, x_hat.shape[2]).argmax(1)\n",
    "    differences = 1. - torch.abs(x_hat_indices - x_indices)\n",
    "    differences = torch.clamp(differences, min=0., max=1.).double()\n",
    "    quality = 100. * torch.mean(differences)\n",
    "    return quality.detach().cpu().numpy()\n",
    "\n",
    "# Charge et convertit un fichier CSV contenant des SMILES en SELFIES + métadonnées\n",
    "def get_selfie_and_smiles_encodings_for_dataset(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    smiles_list = np.asanyarray(df.SMILES)\n",
    "    smiles_alphabet = list(set(\"\".join(smiles_list)))\n",
    "    smiles_alphabet.append(\" \")\n",
    "    largest_smiles_len = len(max(smiles_list, key=len))\n",
    "    print(\"--> Translating SMILES to SELFIES...\")\n",
    "    selfies_list = list(map(sf.encoder, smiles_list))\n",
    "    all_selfies_symbols = sf.get_alphabet_from_selfies(selfies_list)\n",
    "    all_selfies_symbols.add(\"[nop]\")\n",
    "    all_selfies_symbols.add(\".\")\n",
    "    selfies_alphabet = list(all_selfies_symbols)\n",
    "    largest_selfies_len = max(sf.len_selfies(s) for s in selfies_list)\n",
    "    print(\"Finished translating SMILES to SELFIES.\")\n",
    "    return selfies_list, selfies_alphabet, largest_selfies_len, smiles_list, smiles_alphabet, largest_smiles_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a1082f",
   "metadata": {},
   "source": [
    "## Exécution Principale et Génération de Molécules\n",
    "\n",
    "Cette section du notebook exécute le flux principal du projet :\n",
    "\n",
    "1.  **Initialisation et Configuration** :\n",
    "    *   Vérifie si le script est exécuté comme programme principal (`if __name__ == \"__main__\":`).\n",
    "    *   Détermine le répertoire du projet.\n",
    "    *   Charge les paramètres de configuration depuis le fichier `settings.yml`. Ce fichier contient les hyperparamètres pour les données, l'encodeur, le décodeur et l'entraînement.\n",
    "    *   Affiche le périphérique de calcul utilisé (CPU ou GPU).\n",
    "    *   Récupère le type d'encodage (SMILES ou SELFIES) et le nom du fichier de données SMILES depuis les paramètres.\n",
    "\n",
    "2.  **Préparation des Données** :\n",
    "    *   En fonction du `type_of_encoding` spécifié :\n",
    "        *   Si `0` (SMILES) : Charge les SMILES, détermine l'alphabet et la longueur maximale, puis convertit les SMILES en encodage one-hot.\n",
    "        *   Si `1` (SELFIES) : Charge les SMILES, les convertit en SELFIES, détermine l'alphabet et la longueur maximale des SELFIES (avec une limite fixée à 250), puis convertit les SELFIES en encodage one-hot.\n",
    "    *   Calcule les dimensions nécessaires pour les modèles (longueur maximale de la molécule encodée, taille de l'alphabet, dimension de l'entrée one-hot aplatie).\n",
    "\n",
    "3.  **Initialisation du Modèle VAE** :\n",
    "    *   Lit les paramètres spécifiques à l'encodeur, au décodeur et à l'entraînement depuis le dictionnaire `settings`.\n",
    "    *   Instancie les classes `VAEEncoderGumbel` et `VAEDecoderGumbel` avec les paramètres chargés et les dimensions calculées. Les modèles sont déplacés vers le périphérique de calcul approprié.\n",
    "\n",
    "4.  **Chargement de Modèles Pré-entraînés (Optionnel)** :\n",
    "    *   Vérifie si un `pretrained_model` est spécifié dans les paramètres d'entraînement.\n",
    "    *   Si oui, utilise la fonction `load_models` pour charger les poids de l'encodeur et du décodeur sauvegardés à une époque donnée. Les poids sont chargés de manière flexible (`strict=False`) pour permettre des modifications architecturales mineures.\n",
    "\n",
    "5.  **Entraînement du Modèle** :\n",
    "    *   Convertit les données one-hot en tenseurs PyTorch.\n",
    "    *   Mélange les données.\n",
    "    *   Divise les données en ensembles d'entraînement et de validation selon les proportions définies dans `train_valid_test_size`.\n",
    "    *   Appelle la fonction `train_model_gumbel` pour lancer le processus d'entraînement avec les données préparées, les modèles instanciés, et les hyperparamètres d'entraînement.\n",
    "    *   Libère la mémoire GPU non utilisée après l'entraînement.\n",
    "\n",
    "6.  **Génération de Nouvelles Molécules** :\n",
    "    *   Charge les modèles entraînés (ici, spécifiquement ceux de l'époque 119).\n",
    "    *   Itère sur une série de fichiers d'entrée (présumés contenir des données sources pour la génération, par exemple, des points de départ dans l'espace latent ou des molécules de référence encodées).\n",
    "    *   Pour chaque fichier d'entrée :\n",
    "        *   Charge les données (ici, en utilisant `get_selfie_and_smiles_encodings_for_dataset`, ce qui suggère que les fichiers d'entrée contiennent des SMILES qui sont convertis en SELFIES puis en one-hot).\n",
    "        *   Passe les données encodées à travers l'encodeur VAE pour obtenir des représentations latentes (`q`).\n",
    "        *   Passe les représentations latentes à travers le décodeur VAE pour générer de nouvelles molécules encodées (`out_one_hot`).\n",
    "        *   Pour chaque molécule générée :\n",
    "            *   Convertit l'encodage one-hot en indices.\n",
    "            *   Utilise la fonction `clean_and_decode_selfies` pour convertir les indices en une chaîne SELFIES, la nettoyer (supprimer `[nop]`, `.`), puis la décoder en une chaîne SMILES.\n",
    "            *   Ajoute le SMILES généré (s'il est valide) à une liste.\n",
    "    *   Sauvegarde les SMILES générés pour le fichier d'entrée courant dans un fichier CSV.\n",
    "    *   Vide la liste de SMILES et libère la mémoire GPU avant de traiter le fichier suivant.\n",
    "\n",
    "7.  **Fonction `clean_and_decode_selfies`** :\n",
    "    *   Cette fonction (définie à la fin de la cellule de code) prend les indices générés par le décodeur et l'alphabet SELFIES.\n",
    "    *   Convertit les indices en une chaîne SELFIES brute.\n",
    "    *   Nettoie la chaîne SELFIES.\n",
    "    *   Tente de décoder la chaîne SELFIES nettoyée en SMILES.\n",
    "    *   Gère les erreurs de décodage et effectue une validation optionnelle du SMILES résultant avec RDKit.\n",
    "    *   Retourne le SMILES valide (ou une chaîne vide en cas d'échec) et la chaîne SELFIES nettoyée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd4d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partie principale : chargement des paramètres et des données\n",
    "if __name__ == \"__main__\":\n",
    "    project_dir = Path(__file__).resolve().parent\n",
    "    settings_file_path = project_dir.joinpath(\"settings.yml\")\n",
    "    if os.path.exists(settings_file_path):\n",
    "        settings = yaml.safe_load(open(settings_file_path, \"r\"))\n",
    "    else:\n",
    "        print(\"Expected a file settings.yml but didn't find it.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(\"--> Acquiring data...\")\n",
    "    type_of_encoding = settings[\"data\"][\"type_of_encoding\"]\n",
    "    file_name_smiles = settings[\"data\"][\"smiles_file\"]\n",
    "    print(\"Finished acquiring data.\")\n",
    "\n",
    "# Préparation des données selon le type d'encodage (SMILES ou SELFIES)\n",
    "if type_of_encoding == 0:\n",
    "    print(\"Representation: SMILES\")\n",
    "    _, _, _, encoding_list, encoding_alphabet, largest_molecule_len = get_selfie_and_smiles_encodings_for_dataset(\"../\"+file_name_smiles)\n",
    "    print(\"--> Creating one-hot encoding...\")\n",
    "    data = multiple_smile_to_hot(encoding_list, largest_molecule_len, encoding_alphabet)\n",
    "    print(\"Finished creating one-hot encoding.\")\n",
    "elif type_of_encoding == 1:\n",
    "    print(\"Representation: SELFIES\")\n",
    "    encoding_list, encoding_alphabet, largest_molecule_len, _, _, _ = get_selfie_and_smiles_encodings_for_dataset(\"../\"+file_name_smiles)\n",
    "    largest_molecule_len = 250\n",
    "    print(encoding_alphabet)\n",
    "    print(largest_molecule_len)\n",
    "    print(\"--> Creating one-hot encoding...\")\n",
    "    data = multiple_selfies_to_hot(encoding_list, largest_molecule_len, encoding_alphabet)\n",
    "    print(\"Finished creating one-hot encoding.\")\n",
    "else:\n",
    "    print(\"type_of_encoding not in {0, 1}.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Extraction des dimensions pour initialiser les modèles\n",
    "len_max_molec = data.shape[1]\n",
    "len_alphabet = data.shape[2]\n",
    "len_max_mol_one_hot = len_max_molec * len_alphabet\n",
    "print(f\"Alphabet has {len_alphabet} letters, largest molecule is {len_max_molec} letters.\")\n",
    "\n",
    "# Lecture des paramètres depuis settings.yml\n",
    "data_parameters = settings[\"data\"]\n",
    "batch_size = data_parameters[\"batch_size\"]\n",
    "encoder_parameter = settings[\"encoder\"]\n",
    "decoder_parameter = settings[\"decoder\"]\n",
    "training_parameters = settings[\"training\"]\n",
    "\n",
    "# Instanciation du VAE encodeur/décodeur avec Gumbel-Softmax\n",
    "vae_encoder = VAEEncoderGumbel(in_dimension=len_max_mol_one_hot, categorical_dimension=len_alphabet, **encoder_parameter).to(device)\n",
    "vae_decoder = VAEDecoderGumbel(**encoder_parameter, categorical_dimension=len_alphabet, out_dimension=len_max_mol_one_hot).to(device)\n",
    "\n",
    "# Chargement des modèles pré-entraînés si disponibles\n",
    "if training_parameters.get(\"pretrained_model\"):\n",
    "    encoder, decoder = load_models(training_parameters[\"pretrained_model\"])\n",
    "    encoder_dict = {k: v for k, v in encoder.state_dict().items() if k in vae_encoder.state_dict() and encoder.state_dict()[k].size() == vae_encoder.state_dict()[k].size()}\n",
    "    decoder_dict = {k: v for k, v in decoder.state_dict().items() if k in vae_decoder.state_dict() and decoder.state_dict()[k].size() == vae_decoder.state_dict()[k].size()}\n",
    "    vae_encoder.load_state_dict(encoder_dict, strict=False)\n",
    "    vae_decoder.load_state_dict(decoder_dict, strict=False)\n",
    "\n",
    "# Découpage des données en train/validation et lancement de l'entraînement\n",
    "print(\"*\" * 15, \": -->\", device)\n",
    "data = torch.tensor(data, dtype=torch.float).to(device)\n",
    "train_valid_test_size = [0.5, 0.5, 0.0]\n",
    "data = data[torch.randperm(data.size()[0])]\n",
    "idx_train_val = int(len(data) * train_valid_test_size[0])\n",
    "idx_val_test = idx_train_val + int(len(data) * train_valid_test_size[1])\n",
    "data_train = data[0:idx_train_val]\n",
    "data_valid = data[idx_train_val:idx_val_test]\n",
    "print(\"start training\")\n",
    "training_parameters.pop(\"batch_size\", None)\n",
    "train_model_gumbel(**training_parameters, vae_encoder=vae_encoder, vae_decoder=vae_decoder, batch_size=batch_size, data_train=data_train, data_valid=data_valid, alphabet=encoding_alphabet, type_of_encoding=type_of_encoding, sample_len=len_max_molec, categorical_dimension=len_alphabet, logger=False)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Génération de nouvelles molécules à partir de fichiers d'encodage\n",
    "smiles = []\n",
    "encoder, decoder = load_models(119)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Boucle sur les fichiers d'entrée (encodés)\n",
    "for x in range(195):\n",
    "    file_path = f'datasets/datai/{x}.txt'\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File {file_path} does not exist. Please ensure the dataset files are in the correct directory.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Chargement et encodage des données SELFIES\n",
    "    encoding_list, _, _, _, _, _ = get_selfie_and_smiles_encodings_for_dataset(file_path)\n",
    "    data = multiple_selfies_to_hot(encoding_list, largest_molecule_len, encoding_alphabet)\n",
    "    data = torch.FloatTensor(data)\n",
    "    inp_flat_one_hot = data.flatten(start_dim=1).to(device)\n",
    "    \n",
    "    # Encodage latent puis décodage avec le VAE\n",
    "    q = encoder(inp_flat_one_hot).to(device)\n",
    "    out_one_hot, qy = decoder(q, temp=1.0, hard=False)\n",
    "    \n",
    "    # Reconstruction en indices puis en SELFIES puis SMILES\n",
    "    for a in range(len(data)):\n",
    "        target = data[a]\n",
    "        generated = out_one_hot[a].view(target.size())\n",
    "        generated_indices = generated.reshape(-1, generated.shape[1]).argmax(1)\n",
    "        int_to_symbol = dict((i, c) for i, c in enumerate(encoding_alphabet))\n",
    "        smi = clean_and_decode_selfies(generated_indices, encoding_alphabet)\n",
    "        smiles.append(smi)\n",
    "\n",
    "    # Sauvegarde des SMILES générés dans un fichier CSV\n",
    "    smiles_df = pd.DataFrame(smiles)\n",
    "    smiles_df.to_csv(f'datasets/datao/{x}.csv', index=False)\n",
    "    smiles = []\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Fonction pour nettoyer et convertir un encodage SELFIES en SMILES\n",
    "def clean_and_decode_selfies(generated_indices, encoding_alphabet):\n",
    "    # Mapping int → symbole SELFIES\n",
    "    int_to_symbol = {i: c for i, c in enumerate(encoding_alphabet)}\n",
    "\n",
    "    # Décodage brut en SELFIES\n",
    "    selfies = sf.encoding_to_selfies(np.array(generated_indices.cpu()), int_to_symbol, \"label\")\n",
    "    \n",
    "    # Nettoyage : suppression des [nop], des points éventuels\n",
    "    selfies_clean = selfies.replace(\"[nop]\", \"\").replace(\".\", \"\")\n",
    "    \n",
    "    # Tentative de décodage SELFIES → SMILES\n",
    "    try:\n",
    "        smiles = sf.decoder(selfies_clean)\n",
    "        # Validation avec RDKit (optionnel mais utile)\n",
    "        if smiles:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                print(\"Décodage SELFIES réussi mais SMILES invalide.\")\n",
    "                return \"\", selfies_clean\n",
    "    except sf.DecoderError:\n",
    "        print(\"Erreur de décodage SELFIES.\")\n",
    "        smiles = \"\"\n",
    "    \n",
    "    return smiles, selfies_clean\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
